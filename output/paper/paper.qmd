---
title: "Exploring and Predicting House Price in Nanjing: Geographically Imbalanced Distribution Across Districts and the Crucial Role of Unit Price and Bedroom Count in Predictioin"
author: "Yufei Liu"
thanks: "Code and data are available at: https://github.com/Florence-Liu/house-price"
date: today
date-format: long
abstract: "House prices in Nanjing have increased rapidly and became a concern in recent years. This paper examines the relationship between house price in Nanjing, structural attributes of the property, and location using open data collected from Lianjia.com. We then predict house price in Nanjing with different models. We find a geographically-imbalanced distribution of house price in Nanjing with large variance within and between each district. By comparing the MAE, RMSE, and $R^2$, we find the Random Forest model has a better prediction performance than the Multiple Linear Regression model. Unit price and number of bedrooms in the house tend to be importance features for predicting house price in Nanjing. Further work could use spatial data to include the spatial effect in the model, and tune hyperparameters to improve model performance."
format: pdf
number-sections: true
toc: false
bibliography: references.bib
---

# Introduction

House prices in China have grown rapidly since 2000, and prices in cities such as Shanghai, Beijing, and Shenzhen are among the highest in the world today [@citeHouseincrease]. Nanjing, which is located in the Yangtze River Delta in eastern China and approximately 300 km from Shanghai, is the capital city for Jiangsu Province, one of the most economically developed provinces in China [@citeNanjing]. House prices in Nanjing have been a concern due to increased population in recent years [@citeConcern].

In this paper, we investigate how structural attributes and the location of house affect the house price and explore the characteristics of residential housing. We are also interested in predicting house price in Nanjing using different models. We use `Python` to collect data from Lianjia.com and `R` to clean and analyze collected data. We construct a multiple linear regression model with total house price explained by nine other variables representing structural characteristics and location, and a random forest regression model with same variables. We find that the house price in Nanjing is geographically-imbalanced and even the variance within each district is large, reflecting possible income and wealth inequality. Comparing two models with Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Coefficient of Determination ($R^2$), we find that the Random Forest model gives a better prediction performance on training data, testing data, and all datasets, indicating possible non-linear relationships between variables. We also find that unit price and bedroom count play an important role in predicting house price in Nanjing. Further work could include geospatial data to find spatial correlations and use a more comprehensive model including more factors such as surrounding environment and service amenities. We could also consider hyperparameter tuning and shrinkage methods to improvde model performance for both Multiple Linear Regression model and Random Forest model.

The remainder of this paper is structured as follows: @sec-data discusses data collection and data cleaning results, and visualizes the data by graphs and tables; @sec-model introduces two models: a Multiple Linear Regression model and a Random Forest model, and specifies parameters; @sec-result shows the coefficient estimates of the Multiple Linear Regression model, feature importance of the Random Forest model, and comparison of performance for two models; @sec-discussion discusses about model results and implications as well as weaknesses and future work.


# Data {#sec-data}

We used `Python` [@citePython] to obtain the datasets and `R` [@citeR] to do the analysis in this paper. We used pakage `requests` [@citeRequests], `parsel` [@citeParsel], and `csv` [@citeCsv] in `Python` to scrape the data, and then in `R`, we used packages `tidyverse` [@citeTidyverse], `stringr` [@citeStringr], and `here` [@citeHere] to clean and load the data as well as create figures. We used package `latex2expand` [@citeLatex2expand] to add labels to figures, `knitr` [@citeKnitr], `broom` [@citeBroom], and `gt` [@citeGt] to generate tables, and `corrplot` [@citeCorrplot] to make the correlation plot. We also used package `randomForest` [@citeRandomforest] and `Metrics` [@citeMetrics] to build up a Random Forest model and compare the results with Multiple Linear Regression model using different metrics. The color style of the figures was created referring to a R colors cheet-sheet [@citeRcolor].

## Data description {#sec-data_description}

The dataset in this analysis was obtained from Lianjia.com using a web scraping program in Python. Lianjia.com is the website of one of the largest estate brokerage firm in China and the source is open and accessible [@citeLianjia]. We collected 11 datasets with 30,653 observations for 11 different districts in Nanjing, China. To account for temporal variations of housing market, we specifically collected sales property price listed on 22 November, 2023 instead of posted transactions and to consider the consistency, we only collected data for residential houses and discarded data for other types of properties. The datasets includes listed sales prices and structural attributes of the properties including the floor area, the unit price per $\mbox{m}^2$, number of rooms, etc.

The original datasets were merged into one large dataset by districts with missing value removed. After obtaining 5 detailed structural characteristics by splitting `Structrual attributes` variable in original dataset, we created two new variables: `Detailed_Floor` and `Facing_South`. The variable `Detailed_Floor` was obtained from the variable `Total floor`. If the property is in a high floor, the detailed floor will be the total floor multiplied by 0.7; if the property is in a medium floor, the detailed floor will be the total floor multiplied by 0.45; and if the property is in a low floor, the detailed floor will be the total floor multiplied by 0.2. The variable `Facing_South` is a dummy variable with 1 representing the house is south-facing and 0 otherwise. Definitions and descriptions for the 10 variables are listed in @tbl-data. Most of them capture the structural attributes of the house and only `District` indicated an approximate location of the house.

```{r}
#| echo: false
#| message: false
#| warning: false


#### Workspace setup ####
library(tidyverse)
library(knitr)
library(here)
library(latex2exp)
library(randomForest)
library(corrplot)
library(Metrics)
library(broom)
library(gt)

#### Read in the cleaned data ####
data <- read_csv(here("output/data/cleaned_data.csv"), 
                 show_col_types = FALSE)

```

```{r}
#| label: tbl-data
#| tbl-cap: Description for variables
#| echo: false
#| message: false
#| warning: false

var <- c("Total_Price", "Unit_Price", "District", "Area", "Furnished", "Bedroom", "Living_Room", "Total_Floors", "Detailed_Floor", "Facing_South")
type <- c("Continuous", "Continuous", "Categorical", "Continuous", "Categorical", "Discrete", "Discrete", "Discrete", "Discrete", "Dummy")
def <- c("Total house price in thousand yuan", "Unit house price in thousand yuan per square meter", "District where the house is located", "Floor area of the house in square meter ", "Decoration status of the house", "Number of bedrooms", "Number of living/dining rooms", "Total floors of the building", "Floor level of the house", "Whether the house is facing south")
kable(data.frame(var, type, def), 
      col.names = c("Variable", "Type", "Definition"),
      booktabs = TRUE,
      linesep = "")
```

## Data visualization {#sec-data_visualization}

@tbl-price shows a summary for average total house price in thousand yuan, average unit price in thousand yuan/$\mbox{m}^2$, and average floor area in $\mbox{m}^2$ for 11 districts in Nanjing. We find that the highest average house price was in Jianye district while the lowest average house price was in Gaochun district, which is also consistent with the average unit price. However, the average floor area shows a different pattern. The Qinhuai district had the smallest average floor area while Jianye and Pukou districts had the largest average floor area. The difference was not very large within 30 $\mbox{m}^2$. This may relate to geographical information for each districts since the area and population differ from each district. Different from relatively centered average floor area for each districts, the average house price and unit price show a larger variance. This may relate to business activities and industrial development in each district.

```{r}
#| label: tbl-price
#| tbl-cap: Descriptive statistics about house price in each districts
#| echo: false
#| message: false
#| warning: false

data |> group_by(District) |>
  summarise(avg_total = round(mean(Total_Price),1), 
            avg_unit = round(mean(Unit_Price),1),
            avg_area = round(mean(Area),1)) |>
  kable(col.names = c("District", "Average total price",
                      "Average unit price", "Average floor area"),
        booktabs = TRUE, linesep = "")
```

@fig-con, @fig-dis, and @fig-char explore the statistical features of the nine explanatory variables. @fig-con shows the distribution for variable `Area`, `Total_Price`, and `Unit_Price`, @fig-dis shows the distribution for variable `Bedroom`, `Living_Room`, `Total_Floors`, and `Detailed_Floor`. @fig-char shows the proportion of house with 4 different decoration status `Furnished` and orientations `Facing_South` in each district. We find that the total house price, the unit price, and the area were all right-skewed, which means there were some extremely high values for these variables, and the mean values were larger than the median ones. We can also find that most of the values centered in a range. The area mostly centered between 0 to 200 $\mbox{m}^2$, the total price mostly centered between 0 to 1,000,000 yuan, and the unit price had a larger range between 0 to 50,000 yuan.

```{r}
#| label: fig-con
#| fig-cap: Distribution of Area, Total Price, and Unit Price
#| echo: false
#| message: false
#| warning: false

df_con <- data |> select(Total_Price, Unit_Price, Area)
df_con <- gather(df_con)

df_con |> ggplot(aes(x = value)) +
  geom_histogram(fill = "#A8D8B9") +
  facet_wrap(~key, scales = "free") +
  labs(y = "Number of house", x = "Variable value") +
  theme_minimal() +
  theme(axis.text = element_text(size = 7))

```

From @fig-dis we find that most of the listed houses had 2 or 3 bedrooms and 1 to 2 living/dining rooms. The number of rooms was relatively simple with a few houses having over 4 bedrooms and 3 living/dining rooms. However, for total floors of the building and detailed floor, they were various. We find for total floors, there are 3 bursts in approximately 5, 10, and 20, which corresponded to 3 common types of residential buildings in China. However, for detailed floor of listed house, we find that they mostly centered at lower level of the building. This may relate to the sunshine condition as the residential buildings were higher and denser recently, a lower level house may have a bad sunshine and lighting condition.

```{r}
#| label: fig-dis
#| fig-cap: Number of house with different bedroom numbers, living room numbers, total floors, and detailed floor
#| echo: false
#| message: false
#| warning: false

df_dis <- data |> select(Bedroom, Living_Room, Total_Floors, Detailed_Floor)
df_dis <- gather(df_dis)

df_dis |> ggplot(aes(x = value)) +
  geom_bar(fill = "#A8D8B9") +
  facet_wrap(~key, scales = "free") +
  labs(y = "Number of House", x = "Variable value") +
  theme_minimal() +
  theme(axis.text = element_text(size = 7))
```

We find from @fig-char that the number of houses in each districts in our data were similar excluding Gaochun district. This related to the web scraping program we used to obtain the data. However, it indicates that the total number of houses listed in Gaochun district was limited. For the orientation of the house, we find that relatively half of the house is south-facing and in Lishui and Gaochun district the proportions were even higher. It shows a tradition in China that people tend to choose houses facing south, which according to Chinese traditional Feng Shui has positive effect on someone's luck [@citeFengshui]. For decoration status of the house, the data was not that informative since type `Other` occupies a large proportion, which means the information is missing for the house. However, from existing data we find that fully furnished houses on sale has a larger proportion than partly furnished or not furnished house. This may relate to the data we collected that there were a lot of second-hand house on sale instead of newly closed. It is noticeable that houses in the Jianyi district had a much larger proportion of fully furnished house. This may related to the house type there are more fully furnished luxury apartments in Jianyi since the Central Business District (CBD) is located there.

```{r}
#| label: fig-char
#| echo: false
#| message: false
#| warning: false
#| fig-cap: Proportion of house with difference decoration status and whether facing south in 11 districts
#| fig-subcap: 
#|   - "South-facing"
#|   - "Decoration"
#| layout-ncol: 2


data |> group_by(District, Facing_South) |>
  summarise(n = n()) |>
  ggplot(aes(x = District, y = n, fill = factor(Facing_South))) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(y = "Number of house", fill = "Whether south-facing") +
  scale_fill_manual(values = c("#A8D8B9", "#FFD966"), labels = c("No", "Yes")) +
  theme(legend.position = "bottom", axis.text = element_text(size = 8))

data |> group_by(District, Furnished) |>
  summarise(n = n()) |>
  ggplot(aes(x = District, y = n, fill = factor(Furnished))) +
  geom_bar(stat = "identity") +
  labs(y = "Number of house", fill = "Decoration status") +
  theme_minimal() +
  scale_fill_manual(values = c("#7FCCE5", "#FF9A8B", "#A8D8B9", "#FFD966")) +
  theme(legend.position = "bottom", axis.text = element_text(size = 8))
```

@fig-area and @fig-price show how the total house price in each district and Nanjing city as a total related to area and unit price respectively. The blue line is the linear fitted line and the red line is a fitted line without designating methods. From @fig-area we find that although the total price increases with area, the increase rate in each district was different with Lishui district had a notable slow rate compared with others. The increase rate is just the unit price, so this is consistent with @tbl-price. We could also see that some districts had larger variance in area and total price. Pukou district had a large variance of total price with highest total price over 40,000,000 yuan and largest area over 700 $\mbox{m}^2$.

```{r}
#| label: fig-area
#| fig-cap: Relationship between total house price and floor area for 11 districts and Nanjing city in total
#| echo: false
#| message: false
#| warning: false

data |>
  ggplot(aes(x=Area, y=Total_Price)) +
  geom_point(alpha = 0.3, size = 0.8, color = "lightgoldenrod") +
  geom_point(data = transform(data, District = "All in Nanjing"), 
             alpha = 0.5, size = 0.8, color = "lightgoldenrod") +
  geom_smooth(data = transform(data, District = "All in Nanjing"),
              aes(color = "Non-linear"), se=F, size=0.5) +
  geom_smooth(data = transform(data, District = "All in Nanjing"),
              method = "lm", aes(color = "Linear"), se=F, size=0.5) +
  facet_wrap(~District, scales = "free") +
  theme_minimal() +
  geom_smooth(aes(color = "Non-linear"), se=F, size=0.5) +
  geom_smooth(method = "lm", aes(color = "Linear"), se=F, size=0.5) +
  labs(x = TeX(r"(Area in $m^2$)"), y = "Total Price") +
  scale_colour_manual(name = "Line", values = c("steelblue3", "indianred3")) +
  theme(legend.position = "bottom", axis.text = element_text(size = 6),
        strip.text.x = element_text(size = 8))
```

@fig-price further shows how total price changed with unit price. We find that although @tbl-price shows the average unit price for each district was all smaller than 50,000, the highest unit price in most districts was even larger than 80,000. This is consistent with the distribution of unit price that it was right-skewed, a few extremely large values could significantly influence the average value. This is also true for total price that even the average value in each district was smaller than 600, there are still a lot of points at levels higher than even 1,500. This shows the imbalanced distribution of house price, which may also indicate income and wealth inequality.

```{r}
#| label: fig-price
#| fig-cap: Relationship between total house price and unit price for 11 districts and Nanjing city in total
#| echo: false
#| message: false
#| warning: false

data |>
  ggplot(aes(x=Unit_Price, y=Total_Price)) +
  geom_point(alpha = 0.3, size = 0.8, color = "lightgoldenrod") +
  geom_point(data = transform(data, District = "All in Nanjing"), 
             alpha = 0.3, size = 0.8, color = "lightgoldenrod") +
  geom_smooth(data = transform(data, District = "All in Nanjing"),
              aes(color = "Non-linear"), se=F, size=0.5) +
  geom_smooth(data = transform(data, District = "All in Nanjing"),
              method = "lm", aes(color = "Linear"), se=F, size=0.5) +
  facet_wrap(~District, scales = "free") +
  theme_minimal() +
  geom_smooth(aes(color = "Non-linear"), se=F, size=0.5) +
  geom_smooth(method = "lm", aes(color = "Linear"), se=F, size=0.5) +
  labs(x = TeX(r"(Unit Price in yuan/$m^2$)"), y = "Total Price") +
  scale_colour_manual(name = "Line", values = c("steelblue3", "indianred3")) +
  theme(legend.position = "bottom", axis.text = element_text(size = 6),
        strip.text.x = element_text(size = 8))
```

# Model {#sec-model}

We will use two machine learning algorithms in this analysis: a Multiple Linear Regression model (MLR), and a Random Rorest model (RF). We will randomly split our data into training and testing datasets with 80% being training data and 20% being testing data. The training data contains 24,328 observations and the testing data contains 6,082 observations. Models will be performed on training data and assessed their performances based on training data, testing data, and all datasets.

## Multiple Linear Regression {#sec-model_mlg}

The MLR model is shown as:

\begin{align*}
Y = \beta_{0} + \sum_{i=1}^{n} \beta_iX_i + \epsilon = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdots + \beta_nX_n + \epsilon  
\end{align*}

where 

* $Y$ is the response variables `Total_Price`
* $X_i(i = 1,2,\cdots,n)$ are explanatory variables. In this case we have 9 explanatory variables
* $\beta_0$ is the intercept of the model
* $\beta_i(i = 1,2,\cdots,n)$ are regression coefficients
* $\epsilon$ is the random error

The MLR model is used to estimate the coefficients ($\beta_i$) by minimizing Residual Sum of Squares (RSS), and model the linear relationship between the total house price in Nanjing `Total_Price` and multiple predictor variables `Unit_Price`, `Area`, `District`, `Furnished`, `Bedroom`, `Living_Room`, `Total_Floors`, `Detailed_Floor`, and `Facing_South`. We will use function `lm` in `R` to fit the MLR model, it will give us estimates for the coefficients as well as the standard error and t-statistics. The p-value will also be presented, which indicates whether the predictor variable has a statistically significant relationship with `Total_Price`. In general, we set the significance level $\alpha = 0.05$. 

```{r}
#| echo: false
#| warning: false
#| message: false
#| include: false
#### Split training and testing sets ####
set.seed(777)
trainid <- sample(nrow(data), 0.8*nrow(data))
train <- data[trainid,]
test <- data[-trainid,]
```

```{r}
#| label: model
#| echo: false
#| warning: false
#| message: false

model_mlg <- lm(Total_Price ~ ., data = train)
#summary(model_mlg)

model_rf <- randomForest(Total_Price ~ ., data=train, importance = TRUE)

#varImpPlot(model_rf)
```

## Random Forest {#sec-model_rf}

RF is an ensemble learning method that works by growing multiple trees on training data and combining the predictions of the resulting trees [@citeRF]. It improves prediction accuracy of trees and works for both classification and regression tasks. During the process, decision trees are built on random subsets of the training data with replacement and random selection of features, and the final prediction takes the mean of individual tree prediction.

A generalized algorithm for RF with $p$ predictors can be summarized in the following steps [@citeAlgorithm]:

1. For $b=1$ to $B$:
   a. Draw a random bootstrap sample $Z^*$ of size $N$ from the training data (randomly select $N$ samples from the training set with replacement).
   b. Grow a random-forest tree $T_b$ to the bootstrapped data, at each terminal node of the tree, recursively repeat the following steps until the minimum node size $n_{min}$ is reached:
      i. Randomly select $m$ variables from the $p$ variables.
      ii. Split the node into two daughter nodes using features that provides the best split point.
2. The result is the ensemble of trees $\{T_b\}^B_1$.

The final prediction for a new data point $x$ can be expressed as 

$$
{\hat{f}}^B_{\text{rf}}(x)=\frac{1}{B}\sum_{b=1}^BT_b(x)
$$
where $B$ is the number of trees, and $T_b$ is the individual regression tree.

In the process of RF, the number of trees in the forest, the number of candidate variables at each split, and the minimum size of terminal nodes are three important parameters that affect the performance of the RF model [@citeHyper]. A common choice of the number of candidate variable $m$ is $m\approx \sqrt{p}$ for classification trees, and $m=\frac{p}{3}$ for regression trees [@citeM]. We will use `randomForest` function in package `randomForest` in `R` to fit the RF model. The function by default set the minimum size of nodes $n_{min}$ to be 5, and number of trees $\text{ntree}$ to be 500. The number of candidate variables $m$ is determined by $m=\frac{p}{3}$ for regression trees as mentioned before. We will assess the importance of each predictor variable in the RF model by measuring either the percentage increase in Mean Square Error (MSE) or the increase in Node Purity for each split in trees.


# Result {#sec-result}

## Multiplie Linear Regression {#sec-result_mlg}

@tbl-model shows the summary of the multiple linear regression model. We find that `Bedroom` and `Living_Room` have negative effects on the total price, and other predictor variables have positive relationship with total price. We also notice that `District`, `Unit_Price`, and `Bedroom` have relatively strong relationship with `Total_Price`. Predictor variables are significant at level p-value $<0.05$ except for two dummy variables for `Furnished`. The dummy variables for `Not Furnished` and `Part Furnished` show large p-values, indicating they are insignificant with relation to `Total_Price`.

```{r}
#| label: tbl-model
#| tbl-cap: Summary of the multiple linear regression model
#| echo: false
#| message: false
#| warning: false

broom::tidy(model_mlg) |> gt() |>
  tab_spanner(label = md("Multiple Linear Regression"),
    columns = c(estimate, std.error, statistic, p.value)) |>
  fmt_number(columns = vars(estimate), decimals = 1) |>
  fmt_number(columns = vars(std.error), decimals = 1) |>
  fmt_number(columns = vars(statistic), decimals = 1) |>
  fmt_number(columns = vars(p.value), decimals = 3)
```


## Random Forest {#sec-result_mlg}

@fig-model shows the importance of variable of the random forest model based on two metrics, Mean Square Error (MSE), and Node Purity. The percentage increase in MSE ($\%\text{IncMSE}$) is calculated by how much in percentage MSE increases without the predictor. The higher value indicates more important features for making predictions. The increase in Node Purity ($\text{IncNodePurity}$) measure by how much node purity increases when splitting on a specific feature. It is usually calculated by training RSS, and same as $\%\text{IncMSE}$, the higher value indicates higher influence on prediction performance. From @fig-model we find that the three most important predictors are the same based on $\%\text{IncMSE}$ and $\text{IncNodePurity}$, which are `Unit_Price`, `Area`, and `Bedroom`. The two least important predictors are also the same, which are `Furnished` and `Facing_South`.

```{r}
#| label: fig-model
#| echo: false
#| message: false
#| warning: false
#| fig-cap: Variable importance of the random forest model based on MSE and Node Purity
#| fig-subcap: 
#|   - "MSE"
#|   - "Node Purity"
#| layout-ncol: 2

ImpData <- as.data.frame(importance(model_rf))
ImpData$Var.Names <- row.names(ImpData)
ImpData$Var.Names_pur <- factor(ImpData$Var.Names, levels = ImpData$Var.Names[order(ImpData$IncNodePurity)])
ImpData$Var.Names_mse <- factor(ImpData$Var.Names, levels = ImpData$Var.Names[order(ImpData$`%IncMSE`)])

ggplot(ImpData, aes(x=Var.Names_mse, y=`%IncMSE`)) +
  geom_segment( aes(x=Var.Names_mse, xend=Var.Names_mse, y=0, yend=`%IncMSE`), color="skyblue") +
  geom_point(aes(size = `%IncMSE`), color="orange2", alpha=0.6) +
  theme_minimal() +
  labs(x = "Variable") +
  coord_flip() +
  theme(legend.position="bottom", panel.grid.major.y = element_blank(),
        panel.border = element_blank(), axis.ticks.y = element_blank())

ggplot(ImpData, aes(x=Var.Names_pur, y=`IncNodePurity`)) +
  geom_segment(aes(x=Var.Names_pur, xend=Var.Names_pur, y=0, yend=`IncNodePurity`), color="skyblue") +
  geom_point(aes(size = IncNodePurity), color="orange2", alpha=0.6) +
  theme_minimal() +
  labs(x = "Variable") +
  coord_flip() +
  theme(legend.position="bottom", panel.grid.major.y = element_blank(),
        panel.border = element_blank(), axis.ticks.y = element_blank())
```

## Model Evaluation {#sec-evaluation}


| Metrics | Expression |
|:---------:|:------------:|
| MAE |$\frac{1}{n}\sum^{n}_{i=1}|y_i-\hat{y}_i|$|
| RMSE |$\sqrt{\frac{1}{n}\sum^{n}_{i=1}(y_i-\hat{y}_i)^2}$| 
| $R^2$ |$1-\frac{\sum^{n}_{i=1}(y_i-\hat{y}_i)^2}{\sum^{n}_{i=1}(y_i-\bar{y}_i)^2}$|

:Expression for MAE, RMSE, and $R^2$ {#tbl-expression}

There are three metrics being used to evaluate the two models: MAE, RMSE, and $\mbox{R}^2$. Mean Absolute Error (MAE) measures the average absolute difference between the predicted value and actual values [@citeMAE]. Root Mean Squared Error (RMSE) measures the square root of the average squared difference between the predicted value and the actual value [@citeRMSE]. The coefficient of determination ($R^2$) measures the proportion of the total variability in the response variable that can be explained by the model [@citeR2]. The expressions for the three metrics are shown in @tbl-expression. Lower values in MAE and RMSE and higher value (between 0 and 1) in $R^2$ suggest better model performance.


```{r}
#| label: rf
#| echo: false
#| warning: false
#| message: false

predict_rf_all <- predict(model_rf, newdata = data)
mae_rf_all <- round(Metrics::mae(data$Total_Price, predict_rf_all),1)
rmse_rf_all <- round(Metrics::rmse(data$Total_Price, predict_rf_all),1)
r2_rf_all <- round(cor(predict_rf_all, data$Total_Price)^2,3)

predict_rf_test <- predict(model_rf, newdata = test)
mae_rf_test <- round(Metrics::mae(test$Total_Price, predict_rf_test),1)
rmse_rf_test <- round(Metrics::rmse(test$Total_Price, predict_rf_test),1)
r2_rf_test <- round(cor(predict_rf_test, test$Total_Price)^2,3)

predict_rf_train <- predict(model_rf, newdata = train)
mae_rf_train <- round(Metrics::mae(train$Total_Price, predict_rf_train),1)
rmse_rf_train <- round(Metrics::rmse(train$Total_Price, predict_rf_train),1)
r2_rf_train <- round(cor(predict_rf_train, train$Total_Price)^2,3)

```

```{r}
#| label: mlg
#| echo: false
#| warning: false
#| message: false

predict_mlg_all <- predict(model_mlg, newdata = data)
mae_mlg_all <- round(Metrics::mae(data$Total_Price, predict_mlg_all),1)
rmse_mlg_all <- round(Metrics::rmse(data$Total_Price, predict_mlg_all),1)
r2_mlg_all <- round(cor(predict_mlg_all, data$Total_Price)^2,3)

predict_mlg_test <- predict(model_mlg, newdata = test)
mae_mlg_test <- round(Metrics::mae(test$Total_Price, predict_mlg_test),1)
rmse_mlg_test <- round(Metrics::rmse(test$Total_Price, predict_mlg_test),1)
r2_mlg_test  <- round(cor(predict_mlg_test, test$Total_Price)^2,3)

predict_mlg_train <- predict(model_mlg, newdata = train)
mae_mlg_train <- round(Metrics::mae(train$Total_Price, predict_mlg_train),1)
rmse_mlg_train <- round(Metrics::rmse(train$Total_Price, predict_mlg_train),1)
r2_mlg_train <- round(cor(predict_mlg_train, train$Total_Price)^2,3)

```



```{r}
#| label: tbl-metrics
#| tbl-cap: Summary of different metrics for test and train data for two models
#| echo: false
#| message: false
#| warning: false

R2 <- c(r2_mlg_all, r2_mlg_train, r2_mlg_test, r2_rf_all, r2_rf_train, r2_rf_test)
MAE <- c(mae_mlg_all, mae_mlg_train, mae_mlg_test, mae_rf_all, mae_rf_train, mae_rf_test)
RMSE <- c(rmse_mlg_all, rmse_mlg_train, rmse_mlg_test, rmse_rf_all, rmse_rf_train, rmse_rf_test)
Model <- c("MLG all", "MLG train", "MLG test", "RF all", "RF train", "RF test")
metrics <- data.frame(Model, MAE, RMSE, R2)
kable(metrics, booktabs = TRUE, linesep = "", 
      col.names = c("Model", "MAE", "RMSE", "$\\mbox{R}^2$"), escape = F)
  
```


@tbl-metrics shows the results for two models on both training and testing data based on three metrics. We find that overall the RF model yields a better performance on training data, testing data, and all datasets. It has a much lower MAE and RMSE compared with MLR model as well as a higher $R^2$. However, both models have a $R^2$ larger than 0.9, indicating both models could explain over 90% of the total variability in `Total_Price`. We also find that there is no large difference between training and testing performance, suggesting there is minimal overfitting for both models.

# Discussion {#sec-discussion}

## House price distribution in Nanjing {#sec-distribution}

In 2013, the Nanjing Government adjusted the boundaries and administrative divisions of Nanjing. Since then, there are 11 districts in Nanjing with Gulou, Qinhuai, Xuanwu, Jianye districts considered as inner proper while Qixia, Yuhuatai, Pukou, Jiangning, Lishui, Gaochun, Liuhe districts are considered as suburban areas of Nanjing [@citeDivision]. The difference in house price between inner city and suburban areas was also revealed in this paper. From @tbl-price we find that both the average unit price and average total price in inner proper districts are much higher than that of suburban districts. The highest average total price is in the Jianye district with value of 5,406,000 while the lowest average total price is in the Gauchun district with value of 866,800. The large difference in average total price across districts indicates disparities in economical development in each districts. The average floor area in suburban districts is slighter larger than that of inner city. It is consistent with the geographical features of the districts. Suburban area usually has larger available space for real estates, and the real estate developers have difference business strategies and target consumer for inner and suburban areas. Houses in suburban areas are usually designed as two types: one is affordable housing targeted consumers without much money for down payment, another is luxury villa targeted consumers who pursue good environment. Former type of house usually has smaller floor area and lower total price due to its location and transportation convenience. While villas are designed to have large area and better quality with good environment. As a result, we could see from @fig-price and @fig-area, both area and total price in suburban areas vary a lot within each districts especially for Pukou district. The observed variation in housing conditions not only reveals the diverse economic status but also emphasizes the potential disparities in overall quality of life within specific districts. This difference in house quality and living standards among residents within the same district reflects the broader issues of wealth and income inequality as well as social class.

The economical development in each district also contributes the difference in house price across districts. There are two main commercial districts in Nanjing, one in the city center in Gulou district and one in the CBD in Jianye district. Due to limited available space and large population density, high-rise condominiums and luxury apartments are two main types of housing in Gulou and Jianye. These two types of house usually demand higher price due to the modern amenities and location. In addition, commercial districts are accompanied by more job opportunities and higher income level, which attracts those who are seeking more convenient living environment and houses closer to companies to shorten commuting time. The high demand for housing in commercial districts also affects the rental market, thus increasing investment enthusiasm. For Gulou district, it has a third type of house, old apartment built early in 1980s. Since it was developed early, the amenities sometimes function improperly, and management is lax and inefficient with small floor areas. However, such type of house still has a high total price. This is related to its surrounding facilities especially schools. In Nanjing, public schools in compulsory education period that a child may attend is determined by the household registration system, that is primary school and middle school. As a result, parents who wish their children to attend a better public school may choose to buy an apartment within the school district[@citeEdu]. Since it was developed early, many qualified and renowned public schools are located in Gulou district, resulting in the high demand of houses in school district divisions and thus higher house price.


We could also notice the highest house price on sale in Nanjing was about 40,000,000 yuan, which is relatively not very high compared with other economically-developed cities such as Shanghai. One possible reason is that some houses are not listed and sold publicly. Private sales are common among luxurious houses for which price could be over hundreds of million yuan. Another possible reason is government regulation and economic recession. The Chinese government has implemented several policies including land policies, fiscal policies, and monetary policies in various cities to cool down the heated market and housing speculations after 2021 [@citePolicy]. These policies had successfully cooled down the market, however, in an unexpected speed. The sudden policy change and higher unemployment rate have made buying houses a prohibitive choice, and struck the real estate developers who had not been recovered completely from pandemic. Although in 2023, the Nanjing government had announced several promoting policies to help revive the market including decreased interest rate and cancellation of preconditions for buying houses in inner city, the affect was limited. Consumers took a low expectation on current market, greatly reduced investments and speculations on houses. As a result, the demand of house has been decreased compared with 2018, thus affecting the house price dynamics.


## Structral attributes characteristics and performace on predicting house price {#sec-structural}

We have considered specific structural attributes including `Area`, `Furnished`, `Bedroom`, `Living_Room`, `Total_Floors`, `Detailed_Floor`, and `Facing_South`. The floor area distribution reveals a right-skewed pattern, indicating that a significant number of houses falls within the range of 0 to 200 square meters, which also suggests the prevalence of moderate-sized houses. The number of bedrooms centered at 2 to 3 with the number of living rooms centered at 1 to 2, which is a common configuration for houses in Nanjing. It reflects the demand of house for a family of 3 to 4 peoples occupies the market. The concentration of total floors of the house in Nanjing at 10, 15, and 20 corresponds low-, medium-, and high-rise apartments in Nanjing. There is a few houses having total floors more than 30, which reflects tacit rule that in East of Nanjing where the Purple Mountain located, i.e., Qixia district, the height of the building should not exceed the height of Purple Mountain. It is also designed to protect military confidentiality. Most of high-rise apartments were newly built and mostly in West of Nanjing, i.e., Jianye district. Half of the houses on sale were south-facing, which had enough sunshine exposure and naturally bright interiors. According to Chinese traditional Feng Shui, the most auspicious direction of house is south-facing, which could bring luck and good for family harmony. The prevalence of low-rise house on sale was also associated with sunshine condition. Since the residential buildings were built more densely in recent, years, the gap between building became smaller, resulting in few bright and sunshine in low-rise houses. The characteristics of structural attributes reflects family structure, cultural influence, and environmental considerations behind house price.

In predicting house price, these attributes weights differently. For the MLR model `District`, `Unit_Price`, and `Bed_room` shows a strong relationship with `Total_Price` since the magnitudes of the estimates for coefficients are larger than 100. However, `Total_Floors` and `Detailed_Floor` have relatively weak relationship with `Total_Price`. For the RF model, `Area`, `Unit_Price`, and `Bedroom` were more importance in predicting `Total_Price`. In general, `Unit_Price` and `Bedroom` consistently emerge as crucial features for both models, indicating their significance in predicting `Total_Price`.

## Comparison between MLR and RF {#sec-comparison}

As discussion in @sec-evaluation, the RF model gave a better prediction performance compared with MLR model on training data, testing data, and all datasets. However, the MLR model took the advantage of fast training time. The RF model, especially with large datasets and a large number of trees and predictors, can be computationally expensive. In our analysis with approximately 24,000 observations and 9 predictors, the RF model took ten times as much time to train the data compared with MLR model. Additionally, the MLR model has a relatively simple model structure that can be expressed mathematically, and gives estimates for coefficients. The estimates of coefficients indicate both direction and strength of relationship between each predictor and the response variable `Total_Price`, and are more interpretable than the RF model.

Several factors contribute to the better prediction performance of RF model. According to @fig-price and @fig-area, the relationships between `Area`, `Unit_Price`, and `Total_Price` for most districts in Nanjing are non-linear. In this case, the MLR is limited to capture non-linear relationships, thus resulting in worse predictions. Other than non-linear relationships in the dataset, we find that from @fig-cor, `Area` and `Bedroom` are highly positively correlated as well as `Total_Floors` and `Detailed_Floor`. The correlation between `Area` and `Living_Room`, and the correlation between `Bedroom` and `Living_Room` are also positive and quite large. It indicates there exists multicolineaerity in the predictors. The MLG model is sensitive to multicolinearity whlie the RF model is more robust, resulting a better prediction performance of RF model. Another concern is about outliers. Since from @fig-con, the distributions of `Total_Price`, `Area`, and `Unit_Price` are all right-skewed, the dataset contains some extremely high values and possible outliers. In this case, the RF model is also more robust to outliers while the MLR model is more sensitive, contributing to the difference in prediction performance.

```{r}
#| label: fig-cor
#| fig-cap: Correlation between each numeric variables
#| echo: false
#| warning: false
#| message: false

cor_matrix <- cor(data.frame(data$Unit_Price, data$Area, data$Bedroom, data$Living_Room, data$Total_Floors, data$Detailed_Floor, data$Facing_South))

corrplot(cor_matrix, tl.col = "black", tl.cex = 0.8, diag = FALSE, 
         type = "upper", cl.cex = 0.6)
```




## Weakness and future work {#sec-weakness}

This paper analyzed characteristics of house price and associated structural attributes as well as performing predictions, however, several limitation should be acknowledged. One limitation lies in the web scraping program used. Since the data was obtained by web scraping, the data was real-time and credible. However, the website limited maximum scraping page to be 100, which qualified the number of observations. In this case, since the houses was presented in a random order, and we got a large number of observations, our data could still be considered as representative for house price on sale in Nanjing.

In this paper, we focused on structural attributes of the house while there exists other importance factors influencing the house price, such as surrounding environment, public and private facilities, transportation, and location. We only considered difference in districts in our analysis, and we could further extend to more detailed representation for location such as longtitudes and latitudes. The involvement of spatial data could be helpful for analyzing spatial effects within and across each district. We could also consider a more comprehensive model that specifies the effect of facilities and spatial correlation. A Hedonic Pricing model is often used in relevant studies. It classifies influencing factor into four types: structural attributes, accessibility, service amenities, and spatial correlation [@citeHedonic].


For models we used in the analysis, we could also consider some improvements in future work. The validity of MLR model was challenged by the potential multicolinearity concern as shown in @fig-cor, which affected the reliability of the estimates of coefficients. Additionally, although 
the difference between performance on training data and testing data for two models was not significant, we should still be careful about overfitting. The RF model is less prone to overfitting by ensemble learning algorithm, however, a complex tree structure may also arise the problem of overfitting. In this case, we may consider using shrinkage methods such as Lasso or Ridge regression to mitigate the problem of multicolinearity and overfitting for the MLR model. For the RF model, we did not tune hyperparameters in the model, that is the number of tree, the number of candidate predictors at each split, and the minimum size of nodes. Although the model yielded the prediction results with a relatively low MAE and RMSE and a high $R^2$, we could still enhance the model performance by tuning hyperparameter. It will also increase the robustness and generalizability of the model and ensure the optimal performance.


\newpage

# Reference


```{r}
#| include: false
#| echo: false

car::durbinWatsonTest(model_mlg) # autocorrelation

car::ncvTest(model_mlg) # non-constant variance

car::outlierTest(model_mlg) # outlier

car::vif(model_mlg) # multicolinearity

```